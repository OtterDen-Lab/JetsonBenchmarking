# Notes (ssogden)



## Setting up CUDA within a conda environment

Note: I'm going through this on the Orin and then will try the nano

### Installing Conda

```shell
wget https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-aarch64.sh
ll
chmod +x Miniforge3-Linux-aarch64.sh
./Miniforge3-Linux-aarch64.sh
conda create -n tensorflow
```

### Checking jetpack version

```shell
$ sudo apt-cache show nvidia-jetpack
[sudo] password for ssogden:
Sorry, try again.
[sudo] password for ssogden:
Package: nvidia-jetpack
Version: 5.1.1-b56
Architecture: arm64
Maintainer: NVIDIA Corporation
Installed-Size: 194
Depends: nvidia-jetpack-runtime (= 5.1.1-b56), nvidia-jetpack-dev (= 5.1.1-b56)
Homepage: http://developer.nvidia.com/jetson
Priority: standard
Section: metapackages
Filename: pool/main/n/nvidia-jetpack/nvidia-jetpack_5.1.1-b56_arm64.deb
Size: 29304
SHA256: 7b6c8c6cb16028dcd141144b6b0bbaa762616d0a47aafa3c3b720cb02b2c8430
SHA1: 387e4e47133c4235666176032af0f2ec86461dbb
MD5sum: 0a8692031bf35cc46f7a498e2937bda9
Description: NVIDIA Jetpack Meta Package
Description-md5: ad1462289bdbc54909ae109d1d32c0a8
```

I think Steven took care of installing it, but it seems like an apt-get will take care of it.

### Checking out version

Based on the table found [here](https://docs.nvidia.com/deeplearning/frameworks/install-tf-jetson-platform-release-notes/tf-jetson-rel.html#tf-jetson-rel), it looks like I could try TF 2.12.0 or 2.10.1.

### Install TF

I followed the instructions [here](https://docs.nvidia.com/deeplearning/frameworks/install-tf-jetson-platform/index.html), but ran everything as the user, not as root.

The below snippet will install TF for the user in conda.
Notice ***`v512`*** that indicates it's 5.1.2 jetpack version, and ***`2.12.0+nv23.06`*** indicating it's tf 2.12 and nvidia version 23.06.

```shell
pip3 install \
  --extra-index-url https://developer.download.nvidia.com/compute/redist/jp/v512 \
  tensorflow==2.12.0+nv23.06
```

### Testing Whether GPUs are enable

```shell
Python 3.8.10 (default, May 26 2023, 14:05:08)
[GCC 9.4.0] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> import tensorflow as tf
2023-12-03 08:51:06.519841: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
>>> print("Num GPUs Available: ", len(tf.config.list_physical_devices('GPU')))
Num GPUs Available:  1
```

So success!

## Running with GPU

Here's a placeholder note on something interesting I found: https://www.tensorflow.org/guide/gpu#using_multiple_gpus